{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug 16 17:10:53 2020\n",
    "\n",
    "@author: wanxiang.shen@u.nus.edu\n",
    "\"\"\"\n",
    "\n",
    "import warnings, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from joblib import load, dump\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score\n",
    "from sklearn.metrics import auc as calculate_auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from aggmap import AggMap, AggModel, loadmap\n",
    "from aggmap import show\n",
    "np.random.seed(666) #just for reaptable results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob('../data/*.csv.gzip')\n",
    "flist = pd.Series(flist).sort_values().tolist()\n",
    "fall = []\n",
    "for i in flist:\n",
    "    df1 = pd.read_csv(i, compression='gzip', index_col = 0)\n",
    "    df1['class'] = i.split('/')[-1].split('.csv')[0]\n",
    "    fall.append(df1)\n",
    "    \n",
    "df = pd.concat(fall, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df[df.columns[:-1]]\n",
    "dfy = df[df.columns[-1:]]\n",
    "dfx = np.log2(dfx + 1) #apply log2(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save_folder = '/raid/shenwanxiang/transcriptome/pan-cancer'\n",
    "mp = loadmap('/raid/shenwanxiang/agg_mp_object/pan-cancer.mp')\n",
    "\n",
    "\n",
    "X_ns = load(os.path.join(data_save_folder, 'RP1_noisys.data')) \n",
    "X = X_ns[0]\n",
    "Y = pd.get_dummies(dfy['class']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 102)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.fmap_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10446, 1), (10446, 10381), (10446, 102, 102, 1), (10446, 33))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy.shape, dfx.shape, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['01_ACC', '02_BLCA', '03_BRCA', '04_CESC', '05_CHOL', '06_COAD',\n",
       "       '07_DLBC', '08_ESCA', '09_GBM', '10_HNSC', '11_KICH', '12_KIRC',\n",
       "       '13_KIRP', '14_LAML', '15_LGG', '16_LIHC', '17_LUAD', '18_LUSC',\n",
       "       '19_MESO', '20_OV', '21_PAAD', '22_PCPG', '23_PRAD', '24_READ',\n",
       "       '25_SARC', '26_SKCM', '27_STAD', '28_TGCT', '29_THCA', '30_THYM',\n",
       "       '31_UCEC', '32_UCS', '33_UVM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ = pd.get_dummies(dfy['class']).columns\n",
    "class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy['idx'] = range(len(dfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J1-01A-11R-A29S-07</th>\n",
       "      <td>01_ACC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J2-01A-11R-A29S-07</th>\n",
       "      <td>01_ACC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J3-01A-11R-A29S-07</th>\n",
       "      <td>01_ACC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J5-01A-11R-A29S-07</th>\n",
       "      <td>01_ACC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J6-01A-31R-A29S-07</th>\n",
       "      <td>01_ACC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YZ-A980-01A-11R-A405-07</th>\n",
       "      <td>33_UVM</td>\n",
       "      <td>10441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YZ-A982-01A-11R-A405-07</th>\n",
       "      <td>33_UVM</td>\n",
       "      <td>10442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YZ-A983-01A-11R-A405-07</th>\n",
       "      <td>33_UVM</td>\n",
       "      <td>10443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YZ-A984-01A-11R-A405-07</th>\n",
       "      <td>33_UVM</td>\n",
       "      <td>10444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YZ-A985-01A-11R-A405-07</th>\n",
       "      <td>33_UVM</td>\n",
       "      <td>10445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10446 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               class    idx\n",
       "TCGA-OR-A5J1-01A-11R-A29S-07  01_ACC      0\n",
       "TCGA-OR-A5J2-01A-11R-A29S-07  01_ACC      1\n",
       "TCGA-OR-A5J3-01A-11R-A29S-07  01_ACC      2\n",
       "TCGA-OR-A5J5-01A-11R-A29S-07  01_ACC      3\n",
       "TCGA-OR-A5J6-01A-31R-A29S-07  01_ACC      4\n",
       "...                              ...    ...\n",
       "TCGA-YZ-A980-01A-11R-A405-07  33_UVM  10441\n",
       "TCGA-YZ-A982-01A-11R-A405-07  33_UVM  10442\n",
       "TCGA-YZ-A983-01A-11R-A405-07  33_UVM  10443\n",
       "TCGA-YZ-A984-01A-11R-A405-07  33_UVM  10444\n",
       "TCGA-YZ-A985-01A-11R-A405-07  33_UVM  10445\n",
       "\n",
       "[10446 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 fold cv performances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 12s 1ms/sample - loss: 3.0286 - accuracy: 0.1686 - val_loss: 2.0385 - val_accuracy: 0.4541\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 1.2060 - accuracy: 0.6620 - val_loss: 0.6603 - val_accuracy: 0.8214\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.5496 - accuracy: 0.8423 - val_loss: 0.4192 - val_accuracy: 0.8772\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.3673 - accuracy: 0.8945 - val_loss: 0.3175 - val_accuracy: 0.9044\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.2926 - accuracy: 0.9102 - val_loss: 0.2441 - val_accuracy: 0.9247\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.2528 - accuracy: 0.9209 - val_loss: 0.2330 - val_accuracy: 0.9238\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.2091 - accuracy: 0.9325 - val_loss: 0.1893 - val_accuracy: 0.9364\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.1829 - accuracy: 0.9390 - val_loss: 0.1503 - val_accuracy: 0.9523\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.1670 - accuracy: 0.9426 - val_loss: 0.1406 - val_accuracy: 0.9530\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 8s 878us/sample - loss: 0.1521 - accuracy: 0.9458 - val_loss: 0.1487 - val_accuracy: 0.9478\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.1306 - accuracy: 0.9562 - val_loss: 0.1155 - val_accuracy: 0.9605\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.1183 - accuracy: 0.9590 - val_loss: 0.0898 - val_accuracy: 0.9688\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.1113 - accuracy: 0.9587 - val_loss: 0.1021 - val_accuracy: 0.9654\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0920 - accuracy: 0.9650 - val_loss: 0.0826 - val_accuracy: 0.9710\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0899 - accuracy: 0.9680 - val_loss: 0.0610 - val_accuracy: 0.9776\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 888us/sample - loss: 0.0705 - accuracy: 0.9742 - val_loss: 0.0772 - val_accuracy: 0.9734\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.0786 - accuracy: 0.9719 - val_loss: 0.0878 - val_accuracy: 0.9636\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.0763 - accuracy: 0.9702 - val_loss: 0.0370 - val_accuracy: 0.9888\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 9s 961us/sample - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0391 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 884us/sample - loss: 0.0574 - accuracy: 0.9795 - val_loss: 0.0533 - val_accuracy: 0.9821\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.0400 - val_accuracy: 0.9834\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 0.0406 - accuracy: 0.9842 - val_loss: 0.0296 - val_accuracy: 0.9898\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 883us/sample - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.0486 - val_accuracy: 0.9837\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0222 - val_accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.0410 - val_accuracy: 0.9832\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.0312 - accuracy: 0.9901 - val_loss: 0.0311 - val_accuracy: 0.9900\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 889us/sample - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.0402 - val_accuracy: 0.9859\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0263 - val_accuracy: 0.9927\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 888us/sample - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0153 - val_accuracy: 0.9945\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0283 - val_accuracy: 0.9892\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.0146 - val_accuracy: 0.9960\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0083 - val_accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.0215 - val_accuracy: 0.9923\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9943\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.0364 - accuracy: 0.9876 - val_loss: 0.0799 - val_accuracy: 0.9705\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 0.0797 - accuracy: 0.9721 - val_loss: 0.0299 - val_accuracy: 0.9911\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 9s 970us/sample - loss: 4.4276e-04 - accuracy: 1.0000 - val_loss: 2.5543e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 2.4947e-04 - accuracy: 1.0000 - val_loss: 2.1292e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 2.0203e-04 - accuracy: 1.0000 - val_loss: 1.9762e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 1.7998e-04 - accuracy: 1.0000 - val_loss: 1.5028e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 1.5273e-04 - accuracy: 1.0000 - val_loss: 1.3913e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 1.3897e-04 - accuracy: 1.0000 - val_loss: 1.2121e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9401/9401 [==============================] - 8s 844us/sample - loss: 1.2387e-04 - accuracy: 1.0000 - val_loss: 1.0940e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 1.1498e-04 - accuracy: 1.0000 - val_loss: 9.9405e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 1.0209e-04 - accuracy: 1.0000 - val_loss: 9.3951e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 9.2363e-05 - accuracy: 1.0000 - val_loss: 8.7606e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 8.7413e-05 - accuracy: 1.0000 - val_loss: 7.6040e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 8.1313e-05 - accuracy: 1.0000 - val_loss: 7.2709e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 7.1472e-05 - accuracy: 1.0000 - val_loss: 6.5816e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 6.5975e-05 - accuracy: 1.0000 - val_loss: 6.1298e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 6.3499e-05 - accuracy: 1.0000 - val_loss: 5.5770e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 5.6384e-05 - accuracy: 1.0000 - val_loss: 5.3668e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 5.2980e-05 - accuracy: 1.0000 - val_loss: 4.7808e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 4.9294e-05 - accuracy: 1.0000 - val_loss: 4.5684e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 4.6206e-05 - accuracy: 1.0000 - val_loss: 4.1265e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 4.2447e-05 - accuracy: 1.0000 - val_loss: 3.8707e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 3.9571e-05 - accuracy: 1.0000 - val_loss: 3.5737e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 3.6757e-05 - accuracy: 1.0000 - val_loss: 3.9146e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 3.3635e-05 - accuracy: 1.0000 - val_loss: 3.1714e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 3.1649e-05 - accuracy: 1.0000 - val_loss: 3.0142e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 2.9779e-05 - accuracy: 1.0000 - val_loss: 2.6856e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 2.7522e-05 - accuracy: 1.0000 - val_loss: 2.5122e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 2.5974e-05 - accuracy: 1.0000 - val_loss: 2.4198e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 2.3930e-05 - accuracy: 1.0000 - val_loss: 2.1327e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 2.2242e-05 - accuracy: 1.0000 - val_loss: 2.0919e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 2.0678e-05 - accuracy: 1.0000 - val_loss: 1.8637e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 1.9352e-05 - accuracy: 1.0000 - val_loss: 1.7830e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9401/9401 [==============================] - 9s 1ms/sample - loss: 1.8139e-05 - accuracy: 1.0000 - val_loss: 1.6853e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 1.6632e-05 - accuracy: 1.0000 - val_loss: 1.5733e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 1.5765e-05 - accuracy: 1.0000 - val_loss: 1.5068e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 1.4693e-05 - accuracy: 1.0000 - val_loss: 1.3099e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9401/9401 [==============================] - 11s 1ms/sample - loss: 1.3694e-05 - accuracy: 1.0000 - val_loss: 1.2458e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9401/9401 [==============================] - 11s 1ms/sample - loss: 1.2612e-05 - accuracy: 1.0000 - val_loss: 1.1963e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.1986e-05 - accuracy: 1.0000 - val_loss: 1.0710e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9401/9401 [==============================] - 8s 881us/sample - loss: 1.0934e-05 - accuracy: 1.0000 - val_loss: 9.9821e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 1.0202e-05 - accuracy: 1.0000 - val_loss: 9.4635e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 9.6543e-06 - accuracy: 1.0000 - val_loss: 8.4271e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 8.7460e-06 - accuracy: 1.0000 - val_loss: 8.8083e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 8.3761e-06 - accuracy: 1.0000 - val_loss: 7.3145e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 7.5396e-06 - accuracy: 1.0000 - val_loss: 6.8415e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 7.2412e-06 - accuracy: 1.0000 - val_loss: 6.4838e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 6.8434e-06 - accuracy: 1.0000 - val_loss: 6.7138e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 6.3656e-06 - accuracy: 1.0000 - val_loss: 5.5159e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 5.7334e-06 - accuracy: 1.0000 - val_loss: 5.0900e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 5.3779e-06 - accuracy: 1.0000 - val_loss: 5.0623e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 4.9716e-06 - accuracy: 1.0000 - val_loss: 4.4975e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 4.5748e-06 - accuracy: 1.0000 - val_loss: 4.1903e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 4.3956e-06 - accuracy: 1.0000 - val_loss: 4.1593e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 3.9976e-06 - accuracy: 1.0000 - val_loss: 3.5546e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 3.6680e-06 - accuracy: 1.0000 - val_loss: 3.3741e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 3.4717e-06 - accuracy: 1.0000 - val_loss: 3.1378e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9401/9401 [==============================] - 8s 887us/sample - loss: 3.1424e-06 - accuracy: 1.0000 - val_loss: 2.8292e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 2.9738e-06 - accuracy: 1.0000 - val_loss: 2.8781e-06 - val_accuracy: 1.0000\n",
      "test_avg_loss: 0.315, test_avg_acc: 0.954, \n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 11s 1ms/sample - loss: 3.0371 - accuracy: 0.1705 - val_loss: 2.1716 - val_accuracy: 0.4589\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 1.2456 - accuracy: 0.6633 - val_loss: 0.6827 - val_accuracy: 0.8206\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 878us/sample - loss: 0.5473 - accuracy: 0.8450 - val_loss: 0.4378 - val_accuracy: 0.8697\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.3512 - accuracy: 0.8951 - val_loss: 0.2920 - val_accuracy: 0.9120\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.2973 - accuracy: 0.9078 - val_loss: 0.2298 - val_accuracy: 0.9322\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.2420 - accuracy: 0.9247 - val_loss: 0.2207 - val_accuracy: 0.9267\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.2129 - accuracy: 0.9343 - val_loss: 0.1911 - val_accuracy: 0.9369\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.1871 - accuracy: 0.9370 - val_loss: 0.1359 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 9s 924us/sample - loss: 0.1664 - accuracy: 0.9452 - val_loss: 0.1626 - val_accuracy: 0.9428\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.1480 - accuracy: 0.9480 - val_loss: 0.1106 - val_accuracy: 0.9629\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.1244 - accuracy: 0.9580 - val_loss: 0.1186 - val_accuracy: 0.9577\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.1189 - accuracy: 0.9594 - val_loss: 0.0960 - val_accuracy: 0.9675\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.1063 - accuracy: 0.9635 - val_loss: 0.0798 - val_accuracy: 0.9729\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.0987 - val_accuracy: 0.9637\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.0698 - val_accuracy: 0.9757\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 891us/sample - loss: 0.0752 - accuracy: 0.9724 - val_loss: 0.0629 - val_accuracy: 0.9759\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0545 - val_accuracy: 0.9828\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0645 - accuracy: 0.9765 - val_loss: 0.0528 - val_accuracy: 0.9830\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 8s 885us/sample - loss: 0.0534 - accuracy: 0.9814 - val_loss: 0.0433 - val_accuracy: 0.9830\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.0700 - val_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.0381 - val_accuracy: 0.9890\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0418 - accuracy: 0.9849 - val_loss: 0.0479 - val_accuracy: 0.9847\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 886us/sample - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0327 - val_accuracy: 0.9915\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.0251 - val_accuracy: 0.9949\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.0230 - val_accuracy: 0.9930\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0432 - val_accuracy: 0.9845\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0349 - val_accuracy: 0.9881\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0239 - val_accuracy: 0.9938\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0209 - val_accuracy: 0.9927\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0223 - val_accuracy: 0.9924\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 9s 966us/sample - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0042 - val_accuracy: 0.9996\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0785 - val_accuracy: 0.9704\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0371 - val_accuracy: 0.9864\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 878us/sample - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.0274 - val_accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9982\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 7.9088e-04 - accuracy: 0.9999 - val_loss: 3.4074e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 885us/sample - loss: 3.5437e-04 - accuracy: 1.0000 - val_loss: 2.8936e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 2.5856e-04 - accuracy: 1.0000 - val_loss: 2.3767e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 2.1860e-04 - accuracy: 1.0000 - val_loss: 2.0093e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 1.9147e-04 - accuracy: 1.0000 - val_loss: 1.6870e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 1.7217e-04 - accuracy: 1.0000 - val_loss: 1.6108e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 1.5289e-04 - accuracy: 1.0000 - val_loss: 1.4902e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9401/9401 [==============================] - 8s 852us/sample - loss: 1.4309e-04 - accuracy: 1.0000 - val_loss: 1.2614e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.2792e-04 - accuracy: 1.0000 - val_loss: 1.1607e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 1.1038e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 1.0922e-04 - accuracy: 1.0000 - val_loss: 9.7853e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 9.9806e-05 - accuracy: 1.0000 - val_loss: 8.8491e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 9.3927e-05 - accuracy: 1.0000 - val_loss: 8.4757e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 8.8317e-05 - accuracy: 1.0000 - val_loss: 7.8566e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 7.8662e-05 - accuracy: 1.0000 - val_loss: 7.1804e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 7.2819e-05 - accuracy: 1.0000 - val_loss: 6.6965e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 6.8104e-05 - accuracy: 1.0000 - val_loss: 6.0355e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 6.4169e-05 - accuracy: 1.0000 - val_loss: 5.7121e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "9401/9401 [==============================] - 9s 976us/sample - loss: 5.8627e-05 - accuracy: 1.0000 - val_loss: 5.2515e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 5.4219e-05 - accuracy: 1.0000 - val_loss: 4.7892e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 4.9441e-05 - accuracy: 1.0000 - val_loss: 4.5019e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9401/9401 [==============================] - 8s 850us/sample - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 4.1571e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 4.3360e-05 - accuracy: 1.0000 - val_loss: 3.8983e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 4.1616e-05 - accuracy: 1.0000 - val_loss: 3.6271e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9401/9401 [==============================] - 8s 852us/sample - loss: 3.7011e-05 - accuracy: 1.0000 - val_loss: 3.5122e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 3.4607e-05 - accuracy: 1.0000 - val_loss: 3.2410e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 3.2466e-05 - accuracy: 1.0000 - val_loss: 2.8714e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 2.9969e-05 - accuracy: 1.0000 - val_loss: 2.8208e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 2.7287e-05 - accuracy: 1.0000 - val_loss: 2.7480e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 2.6859e-05 - accuracy: 1.0000 - val_loss: 2.3071e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9401/9401 [==============================] - 8s 847us/sample - loss: 2.5002e-05 - accuracy: 1.0000 - val_loss: 2.3218e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 2.2439e-05 - accuracy: 1.0000 - val_loss: 1.9681e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 2.1350e-05 - accuracy: 1.0000 - val_loss: 1.8525e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 1.9116e-05 - accuracy: 1.0000 - val_loss: 1.8160e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 1.8128e-05 - accuracy: 1.0000 - val_loss: 1.6397e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 1.6863e-05 - accuracy: 1.0000 - val_loss: 1.5074e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 1.5186e-05 - accuracy: 1.0000 - val_loss: 1.3782e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 1.4248e-05 - accuracy: 1.0000 - val_loss: 1.3296e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.3293e-05 - accuracy: 1.0000 - val_loss: 1.1990e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 1.2416e-05 - accuracy: 1.0000 - val_loss: 1.2217e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 1.2205e-05 - accuracy: 1.0000 - val_loss: 1.0553e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 1.0510e-05 - accuracy: 1.0000 - val_loss: 9.2088e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 9.7405e-06 - accuracy: 1.0000 - val_loss: 9.0705e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 9.7045e-06 - accuracy: 1.0000 - val_loss: 8.6765e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9401/9401 [==============================] - 8s 883us/sample - loss: 8.2927e-06 - accuracy: 1.0000 - val_loss: 7.5624e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 7.9092e-06 - accuracy: 1.0000 - val_loss: 8.7476e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 7.4510e-06 - accuracy: 1.0000 - val_loss: 6.4998e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9401/9401 [==============================] - 8s 883us/sample - loss: 6.7871e-06 - accuracy: 1.0000 - val_loss: 6.0885e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 6.1572e-06 - accuracy: 1.0000 - val_loss: 5.9269e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 5.9319e-06 - accuracy: 1.0000 - val_loss: 5.1368e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 5.3218e-06 - accuracy: 1.0000 - val_loss: 5.0450e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 5.2998e-06 - accuracy: 1.0000 - val_loss: 4.3605e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9401/9401 [==============================] - 9s 995us/sample - loss: 4.4980e-06 - accuracy: 1.0000 - val_loss: 4.1454e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 4.2620e-06 - accuracy: 1.0000 - val_loss: 3.8700e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 3.9366e-06 - accuracy: 1.0000 - val_loss: 3.9341e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 3.6898e-06 - accuracy: 1.0000 - val_loss: 3.4489e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 3.3571e-06 - accuracy: 1.0000 - val_loss: 2.9820e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 3.1152e-06 - accuracy: 1.0000 - val_loss: 2.8226e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 2.9410e-06 - accuracy: 1.0000 - val_loss: 2.5168e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 2.6206e-06 - accuracy: 1.0000 - val_loss: 2.4621e-06 - val_accuracy: 1.0000\n",
      "test_avg_loss: 0.353, test_avg_acc: 0.950, \n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 9s 961us/sample - loss: 3.0905 - accuracy: 0.1523 - val_loss: 2.2654 - val_accuracy: 0.4425\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.2813 - accuracy: 0.6480 - val_loss: 0.7928 - val_accuracy: 0.7470\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 0.5990 - accuracy: 0.8215 - val_loss: 0.4329 - val_accuracy: 0.8722\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 0.4053 - accuracy: 0.8784 - val_loss: 0.3887 - val_accuracy: 0.8876\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.3164 - accuracy: 0.9011 - val_loss: 0.3022 - val_accuracy: 0.9035\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.2550 - accuracy: 0.9182 - val_loss: 0.2138 - val_accuracy: 0.9309\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.2165 - accuracy: 0.9322 - val_loss: 0.1856 - val_accuracy: 0.9371\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.1962 - accuracy: 0.9327 - val_loss: 0.1878 - val_accuracy: 0.9375\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 0.1805 - accuracy: 0.9417 - val_loss: 0.1525 - val_accuracy: 0.9522\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 0.1490 - accuracy: 0.9489 - val_loss: 0.1387 - val_accuracy: 0.9527\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.1396 - accuracy: 0.9523 - val_loss: 0.1184 - val_accuracy: 0.9614\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.1355 - accuracy: 0.9521 - val_loss: 0.1503 - val_accuracy: 0.9459\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 10s 1ms/sample - loss: 0.1288 - accuracy: 0.9556 - val_loss: 0.0976 - val_accuracy: 0.9667\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.0989 - accuracy: 0.9651 - val_loss: 0.0982 - val_accuracy: 0.9652\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.0924 - accuracy: 0.9656 - val_loss: 0.1132 - val_accuracy: 0.9577\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0789 - accuracy: 0.9709 - val_loss: 0.1043 - val_accuracy: 0.9600\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0787 - accuracy: 0.9710 - val_loss: 0.0716 - val_accuracy: 0.9755\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 0.0693 - accuracy: 0.9744 - val_loss: 0.0466 - val_accuracy: 0.9873\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 8s 881us/sample - loss: 0.0643 - accuracy: 0.9765 - val_loss: 0.0644 - val_accuracy: 0.9770\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 0.0585 - accuracy: 0.9790 - val_loss: 0.1005 - val_accuracy: 0.9585\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 0.0556 - accuracy: 0.9792 - val_loss: 0.0302 - val_accuracy: 0.9917\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0403 - accuracy: 0.9850 - val_loss: 0.0351 - val_accuracy: 0.9893\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0453 - accuracy: 0.9836 - val_loss: 0.0343 - val_accuracy: 0.9897\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0305 - val_accuracy: 0.9880\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.0682 - accuracy: 0.9745 - val_loss: 0.1452 - val_accuracy: 0.9623\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.0161 - val_accuracy: 0.9964\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0310 - accuracy: 0.9873 - val_loss: 0.0118 - val_accuracy: 0.9978\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0095 - val_accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0120 - val_accuracy: 0.9982\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0091 - val_accuracy: 0.9982\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.0242 - val_accuracy: 0.9923\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 9s 962us/sample - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0281 - val_accuracy: 0.9892\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0373 - accuracy: 0.9861 - val_loss: 0.0812 - val_accuracy: 0.9756\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.0195 - val_accuracy: 0.9937\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0034 - val_accuracy: 0.9997\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0312 - val_accuracy: 0.9882\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.0018 - accuracy: 0.9998 - val_loss: 7.0578e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 6.0490e-04 - accuracy: 1.0000 - val_loss: 4.8426e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 4.6821e-04 - accuracy: 1.0000 - val_loss: 3.7319e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 3.7746e-04 - accuracy: 1.0000 - val_loss: 3.0305e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 2.9139e-04 - accuracy: 1.0000 - val_loss: 3.0178e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 2.4824e-04 - accuracy: 1.0000 - val_loss: 2.2645e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 2.2122e-04 - accuracy: 1.0000 - val_loss: 1.8688e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 1.9373e-04 - accuracy: 1.0000 - val_loss: 1.6593e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 1.6880e-04 - accuracy: 1.0000 - val_loss: 1.5758e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.5433e-04 - accuracy: 1.0000 - val_loss: 1.5161e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 1.5062e-04 - accuracy: 1.0000 - val_loss: 1.2534e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 1.3356e-04 - accuracy: 1.0000 - val_loss: 1.1861e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 1.1713e-04 - accuracy: 1.0000 - val_loss: 1.1212e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 1.1144e-04 - accuracy: 1.0000 - val_loss: 1.0107e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 1.0551e-04 - accuracy: 1.0000 - val_loss: 8.9070e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 9.1462e-05 - accuracy: 1.0000 - val_loss: 8.3518e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 8.6258e-05 - accuracy: 1.0000 - val_loss: 8.0329e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 7.9621e-05 - accuracy: 1.0000 - val_loss: 7.0978e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 7.4010e-05 - accuracy: 1.0000 - val_loss: 6.5382e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 6.9149e-05 - accuracy: 1.0000 - val_loss: 6.2574e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 6.4901e-05 - accuracy: 1.0000 - val_loss: 5.5220e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 5.9990e-05 - accuracy: 1.0000 - val_loss: 5.2075e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9401/9401 [==============================] - 9s 985us/sample - loss: 5.4391e-05 - accuracy: 1.0000 - val_loss: 4.8387e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 5.0335e-05 - accuracy: 1.0000 - val_loss: 4.7327e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 4.7419e-05 - accuracy: 1.0000 - val_loss: 4.1690e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 4.3214e-05 - accuracy: 1.0000 - val_loss: 3.9378e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 4.0451e-05 - accuracy: 1.0000 - val_loss: 3.4991e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9401/9401 [==============================] - 8s 878us/sample - loss: 3.7894e-05 - accuracy: 1.0000 - val_loss: 3.6824e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 3.4918e-05 - accuracy: 1.0000 - val_loss: 3.2383e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 3.1456e-05 - accuracy: 1.0000 - val_loss: 2.9023e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 2.9570e-05 - accuracy: 1.0000 - val_loss: 2.6431e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 2.7013e-05 - accuracy: 1.0000 - val_loss: 2.4272e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 2.5882e-05 - accuracy: 1.0000 - val_loss: 2.3047e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 2.3679e-05 - accuracy: 1.0000 - val_loss: 2.1607e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 2.3898e-05 - accuracy: 1.0000 - val_loss: 2.0920e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 2.0934e-05 - accuracy: 1.0000 - val_loss: 1.8970e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 1.9243e-05 - accuracy: 1.0000 - val_loss: 1.7095e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 1.8060e-05 - accuracy: 1.0000 - val_loss: 1.6337e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.6486e-05 - accuracy: 1.0000 - val_loss: 1.5466e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.5841e-05 - accuracy: 1.0000 - val_loss: 1.4250e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 1.4043e-05 - accuracy: 1.0000 - val_loss: 1.2531e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 1.2954e-05 - accuracy: 1.0000 - val_loss: 1.1677e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 1.1920e-05 - accuracy: 1.0000 - val_loss: 1.0784e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 1.1254e-05 - accuracy: 1.0000 - val_loss: 1.0118e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 1.0546e-05 - accuracy: 1.0000 - val_loss: 9.4899e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 9.4786e-06 - accuracy: 1.0000 - val_loss: 8.9806e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 9.3776e-06 - accuracy: 1.0000 - val_loss: 8.4612e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 8.4376e-06 - accuracy: 1.0000 - val_loss: 7.7170e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 7.7374e-06 - accuracy: 1.0000 - val_loss: 7.0081e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 7.2676e-06 - accuracy: 1.0000 - val_loss: 6.6172e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 7.0547e-06 - accuracy: 1.0000 - val_loss: 6.8165e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 6.4066e-06 - accuracy: 1.0000 - val_loss: 5.5901e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 5.7915e-06 - accuracy: 1.0000 - val_loss: 5.2252e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 5.2971e-06 - accuracy: 1.0000 - val_loss: 4.7049e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 4.9457e-06 - accuracy: 1.0000 - val_loss: 5.0863e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 4.5768e-06 - accuracy: 1.0000 - val_loss: 4.1891e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 4.2147e-06 - accuracy: 1.0000 - val_loss: 3.8504e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9401/9401 [==============================] - 10s 1ms/sample - loss: 3.9097e-06 - accuracy: 1.0000 - val_loss: 3.4886e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 3.5449e-06 - accuracy: 1.0000 - val_loss: 3.1758e-06 - val_accuracy: 1.0000\n",
      "test_avg_loss: 0.460, test_avg_acc: 0.944, \n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 9s 967us/sample - loss: 2.9406 - accuracy: 0.1925 - val_loss: 1.9255 - val_accuracy: 0.5290\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 1.2292 - accuracy: 0.6632 - val_loss: 0.7248 - val_accuracy: 0.8039\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.5851 - accuracy: 0.8299 - val_loss: 0.4756 - val_accuracy: 0.8659\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 0.3772 - accuracy: 0.8880 - val_loss: 0.3087 - val_accuracy: 0.9128\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 887us/sample - loss: 0.2941 - accuracy: 0.9104 - val_loss: 0.2641 - val_accuracy: 0.9199\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 0.2520 - accuracy: 0.9205 - val_loss: 0.2259 - val_accuracy: 0.9298\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.2168 - accuracy: 0.9298 - val_loss: 0.1777 - val_accuracy: 0.9416\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.1844 - accuracy: 0.9425 - val_loss: 0.1423 - val_accuracy: 0.9525\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.1777 - accuracy: 0.9397 - val_loss: 0.1273 - val_accuracy: 0.9596\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 0.1515 - accuracy: 0.9487 - val_loss: 0.1300 - val_accuracy: 0.9553\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.1378 - accuracy: 0.9549 - val_loss: 0.1081 - val_accuracy: 0.9630\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 848us/sample - loss: 0.1226 - accuracy: 0.9586 - val_loss: 0.1034 - val_accuracy: 0.9642\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 0.1194 - accuracy: 0.9573 - val_loss: 0.0987 - val_accuracy: 0.9684\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 0.0968 - accuracy: 0.9662 - val_loss: 0.1024 - val_accuracy: 0.9619\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 8s 851us/sample - loss: 0.0838 - accuracy: 0.9707 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.0728 - accuracy: 0.9736 - val_loss: 0.0542 - val_accuracy: 0.9842\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.0684 - val_accuracy: 0.9779\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.0626 - val_accuracy: 0.9753\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.0413 - val_accuracy: 0.9859\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.0670 - val_accuracy: 0.9764\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 10s 1ms/sample - loss: 0.0561 - accuracy: 0.9801 - val_loss: 0.0452 - val_accuracy: 0.9859\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.0590 - val_accuracy: 0.9781\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.0564 - accuracy: 0.9804 - val_loss: 0.0239 - val_accuracy: 0.9956\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0116 - val_accuracy: 0.9972\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0205 - val_accuracy: 0.9947\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0267 - val_accuracy: 0.9926\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.0336 - val_accuracy: 0.9882\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0167 - val_accuracy: 0.9956\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0142 - val_accuracy: 0.9971\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 878us/sample - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0655 - val_accuracy: 0.9769\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0288 - val_accuracy: 0.9895\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0162 - val_accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 848us/sample - loss: 0.0045 - accuracy: 0.9990 - val_loss: 9.3738e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.4217e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 5.0986e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 5.9099e-04 - accuracy: 1.0000 - val_loss: 2.8924e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 2.7290e-04 - accuracy: 1.0000 - val_loss: 2.4082e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 2.4232e-04 - accuracy: 1.0000 - val_loss: 2.1710e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 2.0984e-04 - accuracy: 1.0000 - val_loss: 1.8986e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 1.9350e-04 - accuracy: 1.0000 - val_loss: 1.6896e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9401/9401 [==============================] - 9s 978us/sample - loss: 1.6915e-04 - accuracy: 1.0000 - val_loss: 1.6383e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 1.5576e-04 - accuracy: 1.0000 - val_loss: 1.3999e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 1.4684e-04 - accuracy: 1.0000 - val_loss: 1.4963e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 1.3575e-04 - accuracy: 1.0000 - val_loss: 1.2673e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9401/9401 [==============================] - 8s 881us/sample - loss: 1.2115e-04 - accuracy: 1.0000 - val_loss: 1.0818e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 1.1499e-04 - accuracy: 1.0000 - val_loss: 9.6314e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 1.0235e-04 - accuracy: 1.0000 - val_loss: 8.7364e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 9.1482e-05 - accuracy: 1.0000 - val_loss: 8.1748e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 9.3012e-05 - accuracy: 1.0000 - val_loss: 7.5583e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 7.5785e-05 - accuracy: 1.0000 - val_loss: 6.6218e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 7.0499e-05 - accuracy: 1.0000 - val_loss: 6.4199e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 6.4788e-05 - accuracy: 1.0000 - val_loss: 5.6383e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 5.8417e-05 - accuracy: 1.0000 - val_loss: 5.1410e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 5.7565e-05 - accuracy: 1.0000 - val_loss: 4.7801e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "9401/9401 [==============================] - 8s 852us/sample - loss: 4.9441e-05 - accuracy: 1.0000 - val_loss: 4.9859e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 4.4678e-05 - accuracy: 1.0000 - val_loss: 4.1421e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 4.1088e-05 - accuracy: 1.0000 - val_loss: 3.6805e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 3.7858e-05 - accuracy: 1.0000 - val_loss: 3.4344e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 3.5238e-05 - accuracy: 1.0000 - val_loss: 3.2556e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 3.2969e-05 - accuracy: 1.0000 - val_loss: 3.0948e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 2.9962e-05 - accuracy: 1.0000 - val_loss: 2.6078e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 2.7562e-05 - accuracy: 1.0000 - val_loss: 2.4740e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 2.5078e-05 - accuracy: 1.0000 - val_loss: 2.2587e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 2.3326e-05 - accuracy: 1.0000 - val_loss: 2.0704e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9401/9401 [==============================] - 8s 856us/sample - loss: 2.1010e-05 - accuracy: 1.0000 - val_loss: 1.9946e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 2.0125e-05 - accuracy: 1.0000 - val_loss: 1.8729e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 1.8212e-05 - accuracy: 1.0000 - val_loss: 1.7020e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 1.6781e-05 - accuracy: 1.0000 - val_loss: 1.7395e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.5559e-05 - accuracy: 1.0000 - val_loss: 1.4978e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9401/9401 [==============================] - 8s 852us/sample - loss: 1.4442e-05 - accuracy: 1.0000 - val_loss: 1.4885e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 1.3960e-05 - accuracy: 1.0000 - val_loss: 1.3551e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9401/9401 [==============================] - 9s 999us/sample - loss: 1.2936e-05 - accuracy: 1.0000 - val_loss: 1.1052e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 1.1773e-05 - accuracy: 1.0000 - val_loss: 1.0125e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.0744e-05 - accuracy: 1.0000 - val_loss: 9.2382e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 9.8132e-06 - accuracy: 1.0000 - val_loss: 8.9353e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 9.1849e-06 - accuracy: 1.0000 - val_loss: 8.0647e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 8.9621e-06 - accuracy: 1.0000 - val_loss: 8.0371e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 8.0665e-06 - accuracy: 1.0000 - val_loss: 7.3047e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9401/9401 [==============================] - 8s 881us/sample - loss: 7.0189e-06 - accuracy: 1.0000 - val_loss: 7.0957e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 6.7365e-06 - accuracy: 1.0000 - val_loss: 6.1844e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9401/9401 [==============================] - 8s 894us/sample - loss: 6.0844e-06 - accuracy: 1.0000 - val_loss: 5.5966e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 5.6003e-06 - accuracy: 1.0000 - val_loss: 5.0844e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 5.2292e-06 - accuracy: 1.0000 - val_loss: 4.7272e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 5.0628e-06 - accuracy: 1.0000 - val_loss: 4.7932e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 5.0901e-06 - accuracy: 1.0000 - val_loss: 4.1025e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 4.6057e-06 - accuracy: 1.0000 - val_loss: 3.5617e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 3.8493e-06 - accuracy: 1.0000 - val_loss: 3.9149e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 3.6325e-06 - accuracy: 1.0000 - val_loss: 3.0178e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 3.2386e-06 - accuracy: 1.0000 - val_loss: 3.0126e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 2.9717e-06 - accuracy: 1.0000 - val_loss: 2.6856e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 2.7561e-06 - accuracy: 1.0000 - val_loss: 2.7791e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 2.5523e-06 - accuracy: 1.0000 - val_loss: 2.2796e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 2.3890e-06 - accuracy: 1.0000 - val_loss: 2.1882e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 2.3889e-06 - accuracy: 1.0000 - val_loss: 1.9837e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9401/9401 [==============================] - 8s 850us/sample - loss: 2.0120e-06 - accuracy: 1.0000 - val_loss: 1.7616e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9401/9401 [==============================] - 8s 879us/sample - loss: 1.8874e-06 - accuracy: 1.0000 - val_loss: 1.7159e-06 - val_accuracy: 1.0000\n",
      "test_avg_loss: 0.355, test_avg_acc: 0.949, \n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 11s 1ms/sample - loss: 2.9692 - accuracy: 0.1926 - val_loss: 1.9451 - val_accuracy: 0.5076\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 1.1426 - accuracy: 0.6866 - val_loss: 0.6650 - val_accuracy: 0.8083\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.5386 - accuracy: 0.8428 - val_loss: 0.4266 - val_accuracy: 0.8769\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.3744 - accuracy: 0.8853 - val_loss: 0.3052 - val_accuracy: 0.9143\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.2858 - accuracy: 0.9119 - val_loss: 0.2344 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.2360 - accuracy: 0.9251 - val_loss: 0.2063 - val_accuracy: 0.9312\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.2101 - accuracy: 0.9340 - val_loss: 0.1623 - val_accuracy: 0.9462\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 0.1852 - accuracy: 0.9373 - val_loss: 0.1707 - val_accuracy: 0.9429\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.1576 - accuracy: 0.9456 - val_loss: 0.1370 - val_accuracy: 0.9526\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 9s 920us/sample - loss: 0.1421 - accuracy: 0.9500 - val_loss: 0.1199 - val_accuracy: 0.9580\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.1240 - accuracy: 0.9562 - val_loss: 0.1103 - val_accuracy: 0.9592\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.1167 - accuracy: 0.9590 - val_loss: 0.1026 - val_accuracy: 0.9675\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.1130 - accuracy: 0.9589 - val_loss: 0.0879 - val_accuracy: 0.9680\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.0977 - accuracy: 0.9643 - val_loss: 0.1305 - val_accuracy: 0.9489\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0850 - accuracy: 0.9710 - val_loss: 0.0762 - val_accuracy: 0.9718\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 0.0697 - accuracy: 0.9750 - val_loss: 0.0658 - val_accuracy: 0.9713\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 0.0662 - accuracy: 0.9750 - val_loss: 0.0481 - val_accuracy: 0.9829\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.0585 - val_accuracy: 0.9807\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 0.0604 - accuracy: 0.9768 - val_loss: 0.0419 - val_accuracy: 0.9837\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0618 - accuracy: 0.9782 - val_loss: 0.0614 - val_accuracy: 0.9738\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.0672 - val_accuracy: 0.9777\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.0251 - val_accuracy: 0.9927\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.0455 - val_accuracy: 0.9852\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0319 - accuracy: 0.9889 - val_loss: 0.0164 - val_accuracy: 0.9967\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0252 - accuracy: 0.9906 - val_loss: 0.0388 - val_accuracy: 0.9865\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0300 - val_accuracy: 0.9899\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0409 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0442 - val_accuracy: 0.9863\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.0382 - accuracy: 0.9871 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 0.0371 - accuracy: 0.9864 - val_loss: 0.0266 - val_accuracy: 0.9898\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.0114 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 9s 961us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0073 - val_accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 888us/sample - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 8s 888us/sample - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 880us/sample - loss: 0.0648 - accuracy: 0.9804 - val_loss: 0.0810 - val_accuracy: 0.9682\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 0.0626 - accuracy: 0.9782 - val_loss: 0.0283 - val_accuracy: 0.9916\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.0089 - val_accuracy: 0.9978\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 882us/sample - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 8.2182e-04 - accuracy: 1.0000 - val_loss: 3.7127e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9401/9401 [==============================] - 8s 881us/sample - loss: 4.3087e-04 - accuracy: 1.0000 - val_loss: 2.9057e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9401/9401 [==============================] - 8s 885us/sample - loss: 3.0428e-04 - accuracy: 1.0000 - val_loss: 2.3957e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 2.1689e-04 - accuracy: 1.0000 - val_loss: 1.9005e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 1.6072e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 1.6156e-04 - accuracy: 1.0000 - val_loss: 1.6001e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 1.4526e-04 - accuracy: 1.0000 - val_loss: 1.3312e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 1.3200e-04 - accuracy: 1.0000 - val_loss: 1.1558e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 1.1463e-04 - accuracy: 1.0000 - val_loss: 1.0383e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.0457e-04 - accuracy: 1.0000 - val_loss: 9.3503e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 9.4066e-05 - accuracy: 1.0000 - val_loss: 9.0279e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 8.8083e-05 - accuracy: 1.0000 - val_loss: 7.9312e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9401/9401 [==============================] - 8s 852us/sample - loss: 8.0522e-05 - accuracy: 1.0000 - val_loss: 7.2658e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 7.4471e-05 - accuracy: 1.0000 - val_loss: 6.7417e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 6.6752e-05 - accuracy: 1.0000 - val_loss: 6.1490e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 6.3155e-05 - accuracy: 1.0000 - val_loss: 5.6164e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9401/9401 [==============================] - 8s 872us/sample - loss: 5.8163e-05 - accuracy: 1.0000 - val_loss: 5.1637e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 5.3423e-05 - accuracy: 1.0000 - val_loss: 4.8172e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9401/9401 [==============================] - 9s 966us/sample - loss: 4.9557e-05 - accuracy: 1.0000 - val_loss: 4.7273e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 4.7823e-05 - accuracy: 1.0000 - val_loss: 4.3324e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 4.3328e-05 - accuracy: 1.0000 - val_loss: 3.8555e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 4.0232e-05 - accuracy: 1.0000 - val_loss: 3.6180e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 3.6590e-05 - accuracy: 1.0000 - val_loss: 3.2885e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 3.4633e-05 - accuracy: 1.0000 - val_loss: 3.4193e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 3.2773e-05 - accuracy: 1.0000 - val_loss: 2.8187e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9401/9401 [==============================] - 8s 850us/sample - loss: 3.0003e-05 - accuracy: 1.0000 - val_loss: 2.6496e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9401/9401 [==============================] - 8s 867us/sample - loss: 2.7013e-05 - accuracy: 1.0000 - val_loss: 2.5163e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 2.6023e-05 - accuracy: 1.0000 - val_loss: 2.3759e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 2.4238e-05 - accuracy: 1.0000 - val_loss: 2.1620e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 2.2182e-05 - accuracy: 1.0000 - val_loss: 2.1115e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 2.0883e-05 - accuracy: 1.0000 - val_loss: 1.8923e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 1.9636e-05 - accuracy: 1.0000 - val_loss: 1.7598e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 1.8236e-05 - accuracy: 1.0000 - val_loss: 2.1393e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 1.7576e-05 - accuracy: 1.0000 - val_loss: 1.5819e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 1.5778e-05 - accuracy: 1.0000 - val_loss: 1.3825e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 1.4040e-05 - accuracy: 1.0000 - val_loss: 1.3164e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 1.3207e-05 - accuracy: 1.0000 - val_loss: 1.1797e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 1.2642e-05 - accuracy: 1.0000 - val_loss: 1.1353e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 1.1488e-05 - accuracy: 1.0000 - val_loss: 1.0105e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 1.0621e-05 - accuracy: 1.0000 - val_loss: 9.4439e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9401/9401 [==============================] - 8s 850us/sample - loss: 9.8454e-06 - accuracy: 1.0000 - val_loss: 9.0426e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 9.2424e-06 - accuracy: 1.0000 - val_loss: 8.2422e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 8.8569e-06 - accuracy: 1.0000 - val_loss: 7.6412e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9401/9401 [==============================] - 8s 842us/sample - loss: 8.0110e-06 - accuracy: 1.0000 - val_loss: 7.4012e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 7.4355e-06 - accuracy: 1.0000 - val_loss: 6.5795e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9401/9401 [==============================] - 8s 868us/sample - loss: 6.9072e-06 - accuracy: 1.0000 - val_loss: 6.1214e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9401/9401 [==============================] - 8s 843us/sample - loss: 6.5014e-06 - accuracy: 1.0000 - val_loss: 5.6174e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 5.9285e-06 - accuracy: 1.0000 - val_loss: 5.2755e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9401/9401 [==============================] - 8s 854us/sample - loss: 5.4117e-06 - accuracy: 1.0000 - val_loss: 4.8297e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9401/9401 [==============================] - 8s 866us/sample - loss: 5.0644e-06 - accuracy: 1.0000 - val_loss: 4.7286e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 4.7667e-06 - accuracy: 1.0000 - val_loss: 4.9275e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9401/9401 [==============================] - 9s 998us/sample - loss: 4.5918e-06 - accuracy: 1.0000 - val_loss: 4.0569e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 4.0483e-06 - accuracy: 1.0000 - val_loss: 3.8724e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9401/9401 [==============================] - 8s 853us/sample - loss: 3.8355e-06 - accuracy: 1.0000 - val_loss: 3.3168e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 3.4648e-06 - accuracy: 1.0000 - val_loss: 3.2193e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9401/9401 [==============================] - 8s 863us/sample - loss: 3.2639e-06 - accuracy: 1.0000 - val_loss: 3.0239e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9401/9401 [==============================] - 8s 844us/sample - loss: 3.0713e-06 - accuracy: 1.0000 - val_loss: 2.6830e-06 - val_accuracy: 1.0000\n",
      "test_avg_loss: 0.431, test_avg_acc: 0.951, \n",
      "\n",
      " input train and test X shape is (9401, 102, 102, 1), (1045, 102, 102, 1) \n",
      "{'epochs': 100, 'lr': 0.001, 'conv1_kernel_size': 13, 'dense_layers': [128], 'dense_avf': 'relu', 'batch_size': 64, 'dropout': 0.0, 'batch_norm': False, 'n_inception': 2, 'monitor': 'val_loss', 'patience': 10000, 'random_state': 32, 'verbose': 1, 'name': 'AggMap MultiClass Estimator', 'gpuid': '6'}\n",
      "Train on 9401 samples, validate on 9401 samples\n",
      "Epoch 1/100\n",
      "9401/9401 [==============================] - 9s 968us/sample - loss: 2.9114 - accuracy: 0.2021 - val_loss: 1.7860 - val_accuracy: 0.5616\n",
      "Epoch 2/100\n",
      "9401/9401 [==============================] - 8s 855us/sample - loss: 1.1185 - accuracy: 0.6852 - val_loss: 0.6617 - val_accuracy: 0.7913\n",
      "Epoch 3/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 0.5403 - accuracy: 0.8448 - val_loss: 0.4552 - val_accuracy: 0.8633\n",
      "Epoch 4/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.3711 - accuracy: 0.8892 - val_loss: 0.2949 - val_accuracy: 0.9165\n",
      "Epoch 5/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.2884 - accuracy: 0.9092 - val_loss: 0.2740 - val_accuracy: 0.9075\n",
      "Epoch 6/100\n",
      "9401/9401 [==============================] - 8s 876us/sample - loss: 0.2484 - accuracy: 0.9217 - val_loss: 0.2627 - val_accuracy: 0.9092\n",
      "Epoch 7/100\n",
      "9401/9401 [==============================] - 8s 858us/sample - loss: 0.2204 - accuracy: 0.9293 - val_loss: 0.1784 - val_accuracy: 0.9438\n",
      "Epoch 8/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.1951 - accuracy: 0.9334 - val_loss: 0.1446 - val_accuracy: 0.9518\n",
      "Epoch 9/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.1691 - accuracy: 0.9419 - val_loss: 0.1406 - val_accuracy: 0.9514\n",
      "Epoch 10/100\n",
      "9401/9401 [==============================] - 8s 862us/sample - loss: 0.1605 - accuracy: 0.9462 - val_loss: 0.1347 - val_accuracy: 0.9554\n",
      "Epoch 11/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.1377 - accuracy: 0.9525 - val_loss: 0.1284 - val_accuracy: 0.9513\n",
      "Epoch 12/100\n",
      "9401/9401 [==============================] - 8s 874us/sample - loss: 0.1310 - accuracy: 0.9530 - val_loss: 0.1104 - val_accuracy: 0.9606\n",
      "Epoch 13/100\n",
      "9401/9401 [==============================] - 8s 860us/sample - loss: 0.1152 - accuracy: 0.9603 - val_loss: 0.0984 - val_accuracy: 0.9675\n",
      "Epoch 14/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 0.0959 - accuracy: 0.9651 - val_loss: 0.1055 - val_accuracy: 0.9610\n",
      "Epoch 15/100\n",
      "9401/9401 [==============================] - 9s 1ms/sample - loss: 0.0883 - accuracy: 0.9681 - val_loss: 0.0782 - val_accuracy: 0.9722\n",
      "Epoch 16/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.0858 - accuracy: 0.9688 - val_loss: 0.0844 - val_accuracy: 0.9698\n",
      "Epoch 17/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.0763 - accuracy: 0.9719 - val_loss: 0.0856 - val_accuracy: 0.9699\n",
      "Epoch 18/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0713 - accuracy: 0.9720 - val_loss: 0.0404 - val_accuracy: 0.9847\n",
      "Epoch 19/100\n",
      "9401/9401 [==============================] - 8s 884us/sample - loss: 0.0534 - accuracy: 0.9796 - val_loss: 0.0581 - val_accuracy: 0.9782\n",
      "Epoch 20/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0559 - val_accuracy: 0.9780\n",
      "Epoch 21/100\n",
      "9401/9401 [==============================] - 8s 847us/sample - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.1178 - val_accuracy: 0.9549\n",
      "Epoch 22/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0519 - accuracy: 0.9810 - val_loss: 0.0299 - val_accuracy: 0.9918\n",
      "Epoch 23/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0493 - accuracy: 0.9813 - val_loss: 0.0532 - val_accuracy: 0.9826\n",
      "Epoch 24/100\n",
      "9401/9401 [==============================] - 8s 847us/sample - loss: 0.0464 - accuracy: 0.9806 - val_loss: 0.0822 - val_accuracy: 0.9712\n",
      "Epoch 25/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.0224 - val_accuracy: 0.9945\n",
      "Epoch 26/100\n",
      "9401/9401 [==============================] - 8s 873us/sample - loss: 0.0354 - accuracy: 0.9873 - val_loss: 0.0268 - val_accuracy: 0.9907\n",
      "Epoch 27/100\n",
      "9401/9401 [==============================] - 8s 849us/sample - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0119 - val_accuracy: 0.9976\n",
      "Epoch 28/100\n",
      "9401/9401 [==============================] - 8s 871us/sample - loss: 0.0312 - accuracy: 0.9880 - val_loss: 0.0434 - val_accuracy: 0.9819\n",
      "Epoch 29/100\n",
      "9401/9401 [==============================] - 8s 869us/sample - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.0275 - val_accuracy: 0.9899\n",
      "Epoch 30/100\n",
      "9401/9401 [==============================] - 8s 847us/sample - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.0368 - accuracy: 0.9873 - val_loss: 0.0177 - val_accuracy: 0.9946\n",
      "Epoch 32/100\n",
      "9401/9401 [==============================] - 8s 877us/sample - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0279 - val_accuracy: 0.9876\n",
      "Epoch 33/100\n",
      "9401/9401 [==============================] - 8s 847us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0307 - val_accuracy: 0.9861\n",
      "Epoch 34/100\n",
      "9401/9401 [==============================] - 8s 859us/sample - loss: 0.0261 - accuracy: 0.9895 - val_loss: 0.0055 - val_accuracy: 0.9996\n",
      "Epoch 35/100\n",
      "9401/9401 [==============================] - 8s 885us/sample - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0180 - val_accuracy: 0.9930\n",
      "Epoch 36/100\n",
      "9401/9401 [==============================] - 8s 857us/sample - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0227 - val_accuracy: 0.9932\n",
      "Epoch 37/100\n",
      "9401/9401 [==============================] - 8s 865us/sample - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "9401/9401 [==============================] - 9s 972us/sample - loss: 0.0338 - accuracy: 0.9888 - val_loss: 0.0483 - val_accuracy: 0.9835\n",
      "Epoch 39/100\n",
      "9401/9401 [==============================] - 8s 864us/sample - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
      "Epoch 40/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 4.2141e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9401/9401 [==============================] - 8s 875us/sample - loss: 4.1822e-04 - accuracy: 1.0000 - val_loss: 6.0430e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9401/9401 [==============================] - 8s 870us/sample - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "9401/9401 [==============================] - 8s 861us/sample - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.0359 - val_accuracy: 0.9861\n",
      "Epoch 45/100\n",
      "9280/9401 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9902"
     ]
    }
   ],
   "source": [
    "outer_fold = 10\n",
    "\n",
    "each_fold_results = []\n",
    "outer = StratifiedKFold(n_splits = outer_fold, shuffle = True)\n",
    "outer_idx = outer.split(X, dfy.values)\n",
    "\n",
    "print('#'*50  )\n",
    "run_one_res = []\n",
    "for i in range(10):\n",
    "\n",
    "    fold_num = \"fold_%s\" % str(i).zfill(2) \n",
    "    save_path = './fold_results_c1/%s' % fold_num\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    old_save_path = '../fold_results_c1/%s' % fold_num\n",
    "    test_index = pd.read_csv(os.path.join(old_save_path, 'test_true_label.csv'), index_col=0).index\n",
    "    test_idx = dfy[dfy.index.isin(test_index)]['idx'].tolist()\n",
    "    train_idx = dfy[~dfy.index.isin(test_index)]['idx'].tolist()\n",
    "\n",
    "\n",
    "    testY = Y[test_idx]\n",
    "    testX = X[test_idx]\n",
    "\n",
    "    trainX = X[train_idx]\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    test_true_label = pd.DataFrame(testY).idxmax(axis=1).to_frame(name = 'y_true')\n",
    "    test_true_label.index = dfy.iloc[test_idx].index\n",
    "    test_true_label = test_true_label.join(dfy.iloc[test_idx])\n",
    "    test_true_label.to_csv(os.path.join(save_path, 'test_true_label.csv'))\n",
    "\n",
    "\n",
    "    print(\"\\n input train and test X shape is %s, %s \" % (trainX.shape,  testX.shape))\n",
    "\n",
    "    clf = AggModel.MultiClassEstimator(epochs = 100, batch_size = 64, lr = 1e-3,  \n",
    "                                       gpuid = 6, verbose = 1, metric = 'ACC', ) #\n",
    "    clf.fit(trainX, trainY) \n",
    "\n",
    "    clf._model.save(os.path.join(save_path, 'model.h5'))\n",
    "    \n",
    "    test_pred_label = pd.DataFrame(clf.predict(testX)).idxmax(axis=1).to_frame(name = 'y_pred')\n",
    "    test_pred_label.index = test_true_label.index\n",
    "    test_pred_label.to_csv(os.path.join(save_path, 'test_pred_label.csv'))\n",
    "\n",
    "    test_avg_loss, test_avg_acc = clf._model.evaluate(testX, testY, verbose=0)\n",
    "    print('test_avg_loss: %.3f, test_avg_acc: %.3f, ' % (test_avg_loss, test_avg_acc))\n",
    "\n",
    "    each_fold_results.append(test_avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.949282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.951196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.955024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.950192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.950192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.947318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.961686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.954067\n",
       "1  0.950239\n",
       "2  0.943541\n",
       "3  0.949282\n",
       "4  0.951196\n",
       "5  0.955024\n",
       "6  0.950192\n",
       "7  0.950192\n",
       "8  0.947318\n",
       "9  0.961686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(each_fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.951274\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(each_fold_results).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
