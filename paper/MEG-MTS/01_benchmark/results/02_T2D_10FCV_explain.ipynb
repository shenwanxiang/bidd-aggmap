{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "from aggmap import AggMap, AggModel, loadmap\n",
    "from aggmap.AggModel import load_model, save_model\n",
    "from aggmap import show\n",
    "\n",
    "\n",
    "np.random.seed(666) #just for reaptable results\n",
    "\n",
    "\n",
    "def score(dfr):\n",
    "    y_true = dfr.y_true\n",
    "    y_score = dfr.y_score\n",
    "    y_pred = dfr.y_pred\n",
    "\n",
    "    '''\n",
    "    the metrics are taken from orignal paper:\n",
    "    Meta-Signer: Metagenomic Signature Identifier based on Rank Aggregation of Features\n",
    "    https://github.com/YDaiLab/Meta-Signer/blob/bd6a1cd98d1035f848ecb6e53d9ee67a85871db2/src/utils/metasigner_io.py#L34\n",
    "    '''\n",
    "    auc = roc_auc_score(y_true, y_score, average='weighted')        \n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    pres = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print('roc-auc: %.3f, mcc: %.3f, pres: %.3f, recall: %.3f, f1: %.3f' % (auc, mcc, pres, recall, f1))\n",
    "\n",
    "    return auc, mcc, pres, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'T2D'\n",
    "data_path = '../01_data/species_level/%s/' % (task)\n",
    "save_dir = '%s_results' % task\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "dfa = pd.read_csv(os.path.join(data_path, 'abundance.tsv'),sep='\\t', header=None, index_col=0)\n",
    "dfy = pd.read_csv(os.path.join(data_path, 'labels.txt'),sep='\\t', header=None)\n",
    "dfx = dfa.T\n",
    "dfy = pd.get_dummies(dfy[0].map({'t2d':1, 'n':0}))\n",
    "Y = dfy.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10FCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## repeat_seed: 8; fold_00 ##################################################\n",
      "2021-08-17 17:46:59,376 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2021-08-17 17:46:59,397 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 183315/183315 [00:06<00:00, 29322.07it/s]\n",
      "100%|##########| 183315/183315 [00:00<00:00, 1875359.98it/s]\n",
      "100%|##########| 606/606 [00:00<00:00, 791.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:47:06,719 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2021-08-17 17:47:11,260 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/396 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:47:11,710 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 396/396 [00:02<00:00, 141.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.62, 'best_epoch': 10, 'fill': 0.01, 'fold_num': 'fold_01'}\n",
      "{'best_loss': 0.645, 'best_epoch': 9, 'fill': 0.01, 'fold_num': 'fold_03'}\n",
      "{'best_loss': 0.607, 'best_epoch': 8, 'fill': 0.01, 'fold_num': 'fold_05'}\n",
      "{'best_loss': 0.691, 'best_epoch': 2, 'fill': 0.01, 'fold_num': 'fold_07'}\n",
      "{'best_loss': 0.688, 'best_epoch': 2, 'fill': 0.01, 'fold_num': 'fold_09'}\n",
      "2021-08-17 17:49:35,230 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2021-08-17 17:49:35,257 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 183315/183315 [00:06<00:00, 29505.73it/s]\n",
      "100%|##########| 183315/183315 [00:00<00:00, 1541957.97it/s]\n",
      "100%|##########| 606/606 [00:00<00:00, 719.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:49:44,092 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2021-08-17 17:49:45,339 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|#4        | 56/396 [00:00<00:00, 491.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:49:45,736 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 396/396 [00:00<00:00, 1066.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.58, 'best_epoch': 10, 'fill': 1e-05, 'fold_num': 'fold_01'}\n",
      "{'best_loss': 0.658, 'best_epoch': 6, 'fill': 1e-05, 'fold_num': 'fold_03'}\n",
      "{'best_loss': 0.611, 'best_epoch': 8, 'fill': 1e-05, 'fold_num': 'fold_05'}\n",
      "{'best_loss': 0.684, 'best_epoch': 3, 'fill': 1e-05, 'fold_num': 'fold_07'}\n",
      "{'best_loss': 0.678, 'best_epoch': 5, 'fill': 1e-05, 'fold_num': 'fold_09'}\n",
      "2021-08-17 17:52:09,064 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2021-08-17 17:52:09,089 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 183315/183315 [00:06<00:00, 26564.87it/s]\n",
      "100%|##########| 183315/183315 [00:00<00:00, 1623696.69it/s]\n",
      "100%|##########| 606/606 [00:00<00:00, 695.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:52:18,911 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2021-08-17 17:52:20,541 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|#2        | 48/396 [00:00<00:00, 376.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:52:21,335 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 396/396 [00:00<00:00, 815.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.583, 'best_epoch': 10, 'fill': 1e-08, 'fold_num': 'fold_01'}\n",
      "{'best_loss': 0.666, 'best_epoch': 3, 'fill': 1e-08, 'fold_num': 'fold_03'}\n",
      "{'best_loss': 0.6, 'best_epoch': 8, 'fill': 1e-08, 'fold_num': 'fold_05'}\n",
      "{'best_loss': 0.686, 'best_epoch': 3, 'fill': 1e-08, 'fold_num': 'fold_07'}\n",
      "{'best_loss': 0.695, 'best_epoch': 1, 'fill': 1e-08, 'fold_num': 'fold_09'}\n",
      "2021-08-17 17:54:46,313 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2021-08-17 17:54:46,339 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 183315/183315 [00:06<00:00, 27325.12it/s]\n",
      "100%|##########| 183315/183315 [00:00<00:00, 1501572.77it/s]\n",
      "100%|##########| 606/606 [00:00<00:00, 624.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:54:56,009 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2021-08-17 17:54:57,445 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|#2        | 48/396 [00:00<00:00, 367.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 17:54:57,922 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 396/396 [00:00<00:00, 868.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.575, 'best_epoch': 10, 'scale_method': 'minmax', 'fold_num': 'fold_01'}\n",
      "{'best_loss': 0.652, 'best_epoch': 6, 'scale_method': 'minmax', 'fold_num': 'fold_03'}\n",
      "{'best_loss': 0.609, 'best_epoch': 8, 'scale_method': 'minmax', 'fold_num': 'fold_05'}\n",
      "{'best_loss': 0.687, 'best_epoch': 2, 'scale_method': 'minmax', 'fold_num': 'fold_07'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|#2        | 48/396 [00:00<00:00, 437.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.683, 'best_epoch': 2, 'scale_method': 'minmax', 'fold_num': 'fold_09'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|###5      | 140/396 [00:00<00:00, 505.78it/s]"
     ]
    }
   ],
   "source": [
    "gpuid = 7\n",
    "\n",
    "outer_fold = 10\n",
    "repeat_seeds = [8, 16, 32, 64, 128, 256, 1024, 2048, 4096, 8192] #10 repeats random seeds 8, 16, 32, 64, 128\n",
    "\n",
    "each_fold_results = []\n",
    "run_all_res = []\n",
    "\n",
    "for i, repeat_seed in enumerate(repeat_seeds): \n",
    "    outer = StratifiedKFold(n_splits = outer_fold, shuffle = True, random_state = repeat_seed)\n",
    "    outer_idx = outer.split(range(len(dfy)), dfy.idxmax(axis=1))\n",
    "    run_one_res = []\n",
    "    for j, idx in enumerate(outer_idx):\n",
    "        fold_num = \"fold_%s\" % str(j).zfill(2) \n",
    "        print('#'*50 + ' repeat_seed: %s; %s ' % (repeat_seed, fold_num) + '#'*50 )\n",
    "        \n",
    "        train_idx, test_idx = idx\n",
    "        dfx_train = dfx.iloc[train_idx]\n",
    "        dfy_train = dfy.iloc[train_idx]\n",
    "        \n",
    "        ## get best parameters \n",
    "        if (i == 0) & (j == 0):\n",
    "            from tune import finetune_HPs\n",
    "            best_fill, best_scale_method, best_channel_number, best_epochs, batch_size = finetune_HPs(dfx_train, dfy_train, gpuid=gpuid)\n",
    "            featHPs = {\"best_fill\":best_fill, \"best_scale_method\":best_scale_method, \"best_channel_number\":best_channel_number}\n",
    "            dfx = np.log(dfx + best_fill)\n",
    "            mp = AggMap(dfx, metric = 'correlation')\n",
    "            mp = mp.fit(cluster_channels = best_channel_number, verbose = 0, var_thr = 0)\n",
    "            mp.plot_grid(save_dir)\n",
    "            mp.plot_scatter(save_dir)\n",
    "            mp.save(os.path.join(save_dir, 'agg.mp'))\n",
    "            X = mp.batch_transform(dfx.values, scale = best_scale_method) # NaN values should be the lowest value\n",
    "            \n",
    "        testY = Y[test_idx]\n",
    "        testX = X[test_idx]\n",
    "        \n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "\n",
    "        print(\"\\n input train and test X shape is %s, %s \" % (trainX.shape,  testX.shape))\n",
    "\n",
    "        clf = AggModel.MultiClassEstimator(epochs = best_epochs,  batch_size = batch_size, verbose = 0, gpuid=gpuid) #\n",
    "        clf.fit(trainX, trainY)  #, \n",
    "        \n",
    "        ## save model for explaination\n",
    "        if i == 0:\n",
    "            clf.save_model(os.path.join(save_dir, '%s.model' % fold_num))\n",
    "            paras = clf.get_params()\n",
    "            paras.update({'featHPs':featHPs})\n",
    "            pd.Series(paras).to_json(os.path.join(save_dir, 'HPs.json'))\n",
    "\n",
    "        pred_proba = clf.predict_proba(testX)\n",
    "        y_true = testY[:,1] \n",
    "        y_score = pred_proba[:,1]\n",
    "        y_pred = np.argmax(pred_proba, axis=1)\n",
    "        \n",
    "        dfr = pd.DataFrame([y_true, y_score, y_pred]).T\n",
    "        dfr.columns = ['y_true', 'y_score', 'y_pred']\n",
    "        dfr.index = dfy.iloc[test_idx].index\n",
    "        auc, mcc, pres, recall, f1  = score(dfr)\n",
    "        run_one_res.append(dfr)\n",
    "        ts = pd.Series([auc, mcc, pres, recall, f1, i, repeat_seed]).round(3)\n",
    "        ts.index = ['auc', 'mcc', 'pres', 'recall', 'f1', 'i', 'repeat_seed']\n",
    "        print(ts.to_dict())\n",
    "        each_fold_results.append(ts.to_dict())\n",
    "    run_all_res.append(pd.concat(run_one_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc       0.74492\n",
       "mcc       0.38316\n",
       "pres      0.69359\n",
       "recall    0.69004\n",
       "f1        0.68833\n",
       "i         4.50000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(each_fold_results).groupby('repeat_seed').mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc       0.074003\n",
       "mcc       0.155460\n",
       "pres      0.077954\n",
       "recall    0.077341\n",
       "f1        0.077991\n",
       "i         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(each_fold_results).groupby('repeat_seed').std().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(each_fold_results).to_csv(os.path.join(save_dir, 'performance_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|1         | 8/625 [00:00<00:08, 70.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature importance for column 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 625/625 [00:59<00:00, 10.46it/s]\n",
      "  1%|1         | 7/625 [00:00<00:09, 62.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature importance for column 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 625/625 [00:56<00:00, 10.98it/s]\n",
      "  1%|1         | 8/625 [00:00<00:07, 78.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature importance for column 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 625/625 [00:57<00:00, 10.95it/s]\n",
      "  1%|1         | 7/625 [00:00<00:10, 61.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature importance for column 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|#####     | 317/625 [00:27<00:23, 13.26it/s]"
     ]
    }
   ],
   "source": [
    "all_imps = []\n",
    "for i in range(10):\n",
    "    clf = load_model(os.path.join(save_dir, 'fold_%s.model' % str(i).zfill(2)))\n",
    "    dfe = clf.explain_model(mp, clf.X_, clf.y_, binary_task=True, apply_logrithm=False)\n",
    "    df_imp = dfe.col_1_importance.to_frame(name = 'fold_%s_imp' % str(i).zfill(2))\n",
    "    all_imps.append(df_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfe[dfe.columns[:-1]]\n",
    "dfi['scatter_x'] = dfi.v.map(mp.df_embedding.x)\n",
    "dfi['scatter_y'] = dfi.v.map(mp.df_embedding.y)\n",
    "\n",
    "dfimp_all = pd.concat(all_imps, axis=1)\n",
    "dfi = dfi.join(dfimp_all.mean(axis=1).to_frame(name = 'avg_imp'))\n",
    "dfi = dfi.join(dfimp_all)\n",
    "dfi.to_csv(os.path.join(save_dir, 'feature_imp_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
