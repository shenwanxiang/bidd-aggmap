{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import load, dump\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from aggmap import AggMap\n",
    "import aggmap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = P.seed #for the random permutation\n",
    "metric = P.metric  # similarity measurement\n",
    "var_thr = P.var_thr  # feature variance should larger than 0\n",
    "\n",
    "\n",
    "color_list = P.color_list\n",
    "mnist_labels_dict = P.mnist_labels_dict\n",
    "data_save_folder = P.mnist_data_save_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABICAYAAAAZFJRnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAClElEQVR4nO3cMWpUURiG4f8mqVRUxGAhaCGIhYgy2YJbmQ2I9pbiDtyCe3AFGUTMEowoTBewk2OhjSkMgRxP7v2ep5thiu+HKV64w0yttQIASLEzegAAwP8kfgCAKOIHAIgifgCAKOIHAIgifgCAKHtnfWCapnVVrX+/urrarUedJ43zdGczekJXR89GL+jnwWY1ekJXu6tlfzc/14K/nFW1+vZx9IS+rj8ZvaCbTydfR0/o6s6X3dETujqu79vW2v7p96fz/M/P3nTQbtbhhQ67TLbXptETunp4MnpBP++nZf9f1a227O/mvfoxekJX7c2V0RO6+vn8ePSEbu5+eD16QlcvXt4YPaGrV/V201o7OP2+x14AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEET8AQBTxAwBEmVpr//7ANK2rav3n5eOqOuo9aqDbVbUdPaKTJd9W5b65c998Lfm2KvfN3f3W2v7pN8+Mn78+PE2HrbWDC511iSz5viXfVuW+uXPffC35tir3LZXHXgBAFPEDAEQ5b/y867Li8ljyfUu+rcp9c+e++VrybVXuW6Rz/eYHAGDuPPYCAKKIHwAgivgBAKKIHwAgivgBAKL8AsezcIMPRZfbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.palplot(color_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_save_folder):\n",
    "    os.makedirs(data_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() #(x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) orignal(c=1): OR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/01_X_OR1.data']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1) orignal(c=1): OR1\n",
    "_, w, h = x_train.shape\n",
    "trainX_OR1 = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "testX_OR1 = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "dump((trainX_OR1, testX_OR1),  os.path.join(data_save_folder, '01_X_OR1.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal_cols = ['p-%s' % str((i+1)).zfill(len(str(w*h))) for i in range(w*h)]\n",
    "x_train_df = pd.DataFrame(x_train.reshape(x_train.shape[0], w*h), columns = orignal_cols)\n",
    "x_test_df = pd.DataFrame(x_test.reshape(x_test.shape[0], w*h), columns = orignal_cols)\n",
    "shuffled_cols = shuffle(orignal_cols, random_state=seed)\n",
    "x_train_df = x_train_df[shuffled_cols]\n",
    "x_test_df = x_test_df[shuffled_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ORS1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/02_X_ORS1.data']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2) shuffle(c=1): ORS1\n",
    "trainX_ORS1 = x_train_df.values.reshape(-1, w, h, 1)\n",
    "testX_ORS1 = x_test_df.values.reshape(-1, w, h, 1)\n",
    "dump((trainX_ORS1, testX_ORS1),  os.path.join(data_save_folder, '02_X_ORS1.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 22:58:05,401 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2020-10-16 22:58:05,438 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 306936/306936 [00:55<00:00, 5497.24it/s]\n",
      "100%|##########| 306936/306936 [00:00<00:00, 1514056.89it/s]\n",
      "100%|##########| 784/784 [00:02<00:00, 351.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 22:59:03,932 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Calculating distance ...\u001b[0m\n",
      "2020-10-16 22:59:03,968 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - the number of process is 16\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 306936/306936 [00:12<00:00, 25152.40it/s]\n",
      "100%|##########| 306936/306936 [00:00<00:00, 1628116.81it/s]\n",
      "100%|##########| 784/784 [00:01<00:00, 672.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/test.mp']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_train = AggMap(x_train_df, metric = metric)\n",
    "mp_test = AggMap(x_test_df, metric = metric)\n",
    "\n",
    "mp_train.save(os.path.join(data_save_folder, 'train.mp'))\n",
    "mp_test.save(os.path.join(data_save_folder, 'test.mp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03) orignal_shuffle_agglomerate(c=1): ORSAgg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 22:59:22,362 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 22:59:23,258 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 60000/60000 [08:51<00:00, 112.83it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 610.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/03_X_ORSAgg1.data']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## orignal_shuffle_agglomerate(c=1): ORSAgg1\n",
    "mp_ORSAgg1 = mp_train.copy().fit(verbose = 0, \n",
    "                                 var_thr = var_thr, fmap_shape = (w, h),\n",
    "                                 feature_group_list=['feature_point' for i in range(w*h)], \n",
    "                                 group_color_dict = {'feature_point':color_list[0]})\n",
    "\n",
    "trainX_ORSAgg1 = mp_ORSAgg1.batch_transform(x_train_df.values, scale = False, n_jobs = 10)\n",
    "testX_ORSAgg1 = mp_ORSAgg1.batch_transform(x_test_df.values, scale = False, n_jobs = 10)\n",
    "mp_ORSAgg1.save(os.path.join(data_save_folder, 'mp_ORSAgg1.mp'))\n",
    "dump((trainX_ORSAgg1, testX_ORSAgg1),  os.path.join(data_save_folder, '03_X_ORSAgg1.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. cluster channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04) orignal_shuffle_agglomerate_cluster(c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:08:32,882 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2020-10-16 23:08:34,221 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/60000 [00:00<01:51, 535.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:08:35,068 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 60000/60000 [01:49<00:00, 550.24it/s]\n",
      "100%|##########| 10000/10000 [00:18<00:00, 544.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/03_X_ORSAggC3.data']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mp_ORSAggC3 = mp_train.copy().fit(verbose = 0, cluster_channels=3, \n",
    "                                   var_thr = var_thr, fmap_shape = (w, h),\n",
    "                                   group_color_dict = dict(zip(['cluster_%s' % str(i).zfill(2) for i in range(10)],color_list)))\n",
    "trainX_ORSAggC3 = mp_ORSAggC3.batch_transform(x_train_df.values, scale = False, n_jobs = 10)\n",
    "testX_ORSAggC3 = mp_ORSAggC3.batch_transform(x_test_df.values, scale = False, n_jobs = 10)\n",
    "\n",
    "mp_ORSAggC3.save(os.path.join(data_save_folder, 'mp_ORSAggC3.mp'))\n",
    "dump((trainX_ORSAggC3, testX_ORSAggC3),  os.path.join(data_save_folder, '03_X_ORSAggC3.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04) orignal_shuffle_agglomerate_cluster(c=5): ORSAggC5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:10:45,903 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2020-10-16 23:10:47,221 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/60000 [00:00<02:17, 435.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:10:48,072 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 60000/60000 [02:14<00:00, 445.29it/s]\n",
      "100%|##########| 10000/10000 [00:22<00:00, 445.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/04_X_ORSAggC5.data']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_ORSAggC5 = mp_train.copy().fit(verbose = 0, cluster_channels=5, \n",
    "                                  var_thr = var_thr, fmap_shape = (w, h),\n",
    "                                  group_color_dict = dict(zip(['cluster_01', 'cluster_02', 'cluster_03', \n",
    "                                                               'cluster_04', 'cluster_05'],color_list[:4])))\n",
    "\n",
    "trainX_ORSAggC5 = mp_ORSAggC5.batch_transform(x_train_df.values, scale = False, n_jobs = 10)\n",
    "testX_ORSAggC5 = mp_ORSAggC5.batch_transform(x_test_df.values, scale = False, n_jobs = 10)\n",
    "\n",
    "mp_ORSAggC5.save(os.path.join(data_save_folder, 'mp_ORSAggC5.mp'))\n",
    "dump((trainX_ORSAggC5, testX_ORSAggC5),  os.path.join(data_save_folder, '04_X_ORSAggC5.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05) orignal_shuffle_agglomerate_cluster(c=10): ORSAggC10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:13:29,972 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - applying hierarchical clustering to obtain group information ...\u001b[0m\n",
      "2020-10-16 23:13:31,293 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/60000 [00:00<01:44, 576.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 23:13:32,071 - \u001b[32mINFO\u001b[0m - [bidd-aggmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 60000/60000 [01:53<00:00, 529.21it/s]\n",
      "100%|##########| 10000/10000 [00:19<00:00, 522.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/05_X_ORSAggC10.data']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 05) orignal_shuffle_agglomerate_cluster(c=4): ORSAggC4\n",
    "mp_ORSAggC10 = mp_train.copy().fit(verbose = 0, cluster_channels=10, \n",
    "                                   var_thr = var_thr, fmap_shape = (w, h),\n",
    "                                   group_color_dict = dict(zip(['cluster_%s' % str(i).zfill(2) for i in range(10)],color_list)))\n",
    "trainX_ORSAggC10 = mp_ORSAggC10.batch_transform(x_train_df.values, scale = False, n_jobs = 10)\n",
    "testX_ORSAggC10 = mp_ORSAggC10.batch_transform(x_test_df.values, scale = False, n_jobs = 10)\n",
    "\n",
    "mp_ORSAggC10.save(os.path.join(data_save_folder, 'mp_ORSAggC10.mp'))\n",
    "dump((trainX_ORSAggC10, testX_ORSAggC10),  os.path.join(data_save_folder, '05_X_ORSAggC10.data')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dump Gauss nosiy test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 10000/10000 [00:16<00:00, 620.02it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 616.18it/s]\n",
      "100%|##########| 10000/10000 [00:25<00:00, 384.65it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 611.66it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 613.79it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 620.16it/s]\n",
      "100%|##########| 10000/10000 [00:15<00:00, 628.50it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 588.87it/s]\n",
      "100%|##########| 10000/10000 [00:21<00:00, 471.82it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 591.64it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 583.01it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 584.72it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 586.37it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 585.79it/s]\n",
      "100%|##########| 10000/10000 [00:16<00:00, 590.30it/s]\n",
      "100%|##########| 10000/10000 [00:20<00:00, 479.80it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 584.18it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 587.85it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 587.50it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 584.70it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 584.16it/s]\n",
      "100%|##########| 10000/10000 [00:21<00:00, 470.97it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 571.68it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 571.89it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 568.02it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 566.33it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 570.70it/s]\n",
      "100%|##########| 10000/10000 [00:17<00:00, 570.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/raid/shenwanxiang/aggmap/mnist/correlation/testX_noisys_shuffle_ORSAggC10.data']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gauss_noisy(X, c = 0.38):\n",
    "    ''' \n",
    "    X: 4D array, n,w,h,c\n",
    "    '''\n",
    "    X = X/255.\n",
    "    np.random.seed(123)\n",
    "    X = np.clip(X + np.random.normal(size = X.shape, scale = c), 0, 1) * 255\n",
    "    return X\n",
    "\n",
    "stddevs = np.arange(0, 0.8, 0.12)\n",
    "shuffled_cols = shuffle(range(784), random_state=seed)\n",
    "\n",
    "testX_noisys = []\n",
    "testX_noisy_names = []\n",
    "for stddev in stddevs:\n",
    "    testX = x_test.reshape(-1, 28,28, 1)\n",
    "    testX_noisy = gauss_noisy(testX, c = stddev)\n",
    "    testX_noisys.append(testX_noisy)\n",
    "    testX_noisy_names.append('stddev: %.2f' % stddev)\n",
    "dump(testX_noisys,  os.path.join(data_save_folder, 'testX_noisys.data')) \n",
    "\n",
    "\n",
    "testX_noisys_shuffle = []\n",
    "for testX_noisy in testX_noisys:\n",
    "    testX_noisy = testX_noisy.reshape(-1, 28*28)\n",
    "    testX_noisy = testX_noisy.T[shuffled_cols].T.reshape(-1, 28,28, 1)\n",
    "    testX_noisys_shuffle.append(testX_noisy)\n",
    "dump(testX_noisys_shuffle,  os.path.join(data_save_folder, 'testX_noisys_shuffle.data')) \n",
    "    \n",
    "    \n",
    "testX_noisys_shuffle_ORSAgg1 = []\n",
    "for testX_noisy_shuffle in testX_noisys_shuffle:\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, 28*28)\n",
    "    testX_noisy_shuffle = mp_ORSAgg1.batch_transform(testX_noisy_shuffle, scale = False, n_jobs=10)\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, mp_ORSAgg1.fmap_shape[0],mp_ORSAgg1.fmap_shape[1], 1)\n",
    "    testX_noisys_shuffle_ORSAgg1.append(testX_noisy_shuffle)\n",
    "dump(testX_noisys_shuffle_ORSAgg1,  os.path.join(data_save_folder, 'testX_noisys_shuffle_ORSAgg1.data')) \n",
    "    \n",
    "\n",
    "testX_noisys_shuffle_ORSAggC3 = []\n",
    "for testX_noisy_shuffle in testX_noisys_shuffle:\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, 28*28)\n",
    "    testX_noisy_shuffle = mp_ORSAggC3.batch_transform(testX_noisy_shuffle, scale = False, n_jobs=10)\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, mp_ORSAggC3.fmap_shape[0],mp_ORSAggC3.fmap_shape[1], 3)\n",
    "    testX_noisys_shuffle_ORSAggC3.append(testX_noisy_shuffle)\n",
    "dump(testX_noisys_shuffle_ORSAggC3,  os.path.join(data_save_folder, 'testX_noisys_shuffle_ORSAggC3.data')) \n",
    "    \n",
    "    \n",
    "testX_noisys_shuffle_ORSAggC5 = []\n",
    "for testX_noisy_shuffle in testX_noisys_shuffle:\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, 28*28)\n",
    "    testX_noisy_shuffle = mp_ORSAggC5.batch_transform(testX_noisy_shuffle, scale = False, n_jobs=10)\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, mp_ORSAggC5.fmap_shape[0],mp_ORSAggC5.fmap_shape[1], 5)\n",
    "    testX_noisys_shuffle_ORSAggC5.append(testX_noisy_shuffle)\n",
    "dump(testX_noisys_shuffle_ORSAggC5,  os.path.join(data_save_folder, 'testX_noisys_shuffle_ORSAggC5.data')) \n",
    "     \n",
    "    \n",
    "    \n",
    "testX_noisys_shuffle_ORSAggC10 = []\n",
    "for testX_noisy_shuffle in testX_noisys_shuffle:\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, 28*28)\n",
    "    testX_noisy_shuffle = mp_ORSAggC10.batch_transform(testX_noisy_shuffle, scale = False, n_jobs=10)\n",
    "    testX_noisy_shuffle = testX_noisy_shuffle.reshape(-1, mp_ORSAggC10.fmap_shape[0],mp_ORSAggC10.fmap_shape[1], 10)\n",
    "    testX_noisys_shuffle_ORSAggC10.append(testX_noisy_shuffle)\n",
    "dump(testX_noisys_shuffle_ORSAggC10,  os.path.join(data_save_folder, 'testX_noisys_shuffle_ORSAggC10.data')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
